{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOil6UXCELm8VMCk0+h+Ai0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/c0991100247/2025.07.12-PERIC/blob/main/P_ETHI_02_%E5%8F%B8%E6%B3%95%E9%99%A2%E8%A3%81%E5%88%A4%E6%9B%B8%E4%B8%AD%E7%9A%84%E6%95%91%E8%AD%B7%E6%8A%80%E8%A1%93%E5%93%A1_%E5%A4%9A%E6%A8%A1%E6%85%8B%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%81%8B%E7%94%A8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai # 用於Gemini API\n",
        "!pip install -q -U PyMuPDF             # 用於PDF文字擷取 (fitz)"
      ],
      "metadata": {
        "id": "LYQMyq3B1OMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "import fitz # PyMuPDF (for PDF文字擷取)\n",
        "from tqdm.notebook import tqdm\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "from datetime import datetime # 用於日期轉換\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive') # Mount Drive if needed, but keep path general\n",
        "\n",
        "# --- 步驟 0: 設定組態與載入函式庫 ---\n",
        "\n",
        "# 重要：請調整這些路徑以符合您儲存文件和希望輸出文件的位置！\n",
        "# 建議將PDF文件上傳到Colab環境中，或使用Google雲端硬碟並在此處指定正確路徑。\n",
        "# 範例：如果您將PDF上傳到 Colab 的 /content/pdfs 資料夾\n",
        "# PDF_FOLDER_PATH = '/content/pdfs'\n",
        "# 範例：如果您使用 Google 雲端硬碟，且文件在 'My Drive/MyLegalDocs' 資料夾中\n",
        "# drive.mount('/content/drive') # 如果使用雲端硬碟，請取消註解此行\n",
        "# PDF_FOLDER_PATH = '/content/drive/MyDrive/MyLegalDocs'\n",
        "\n",
        "# 請在此處指定您的PDF文件資料夾路徑\n",
        "PDF_FOLDER_PATH = '/content/drive/MyDrive/' # <-- 請修改此路徑\n",
        "\n",
        "# 處理後的資料輸出檔案 (將儲存至指定路徑)\n",
        "# 建議儲存在 Colab 環境中，或 Google 雲端硬碟中的指定位置\n",
        "# 範例：OUTPUT_JSON_PATH = '/content/processed_documents.json'\n",
        "# 範例：OUTPUT_JSON_PATH = '/content/drive/MyDrive/processed_legal_documents.json'\n",
        "\n",
        "# 請在此處指定您的輸出 JSON 檔案路徑\n",
        "OUTPUT_JSON_PATH = '/content/drive/MyDrive/' # <-- 請修改此路徑\n",
        "\n",
        "# Gemini API處理文件數量限制 (設定為 None 處理所有文件)\n",
        "DOCUMENT_PROCESS_LIMIT = None\n",
        "\n",
        "print(\"函式庫載入完成，組態路徑已定義。\")\n",
        "print(f\"請確認並調整以下路徑以符合您的需求:\")\n",
        "print(f\"PDF文件預期路徑: {PDF_FOLDER_PATH}\")\n",
        "print(f\"處理後的資料將儲存至: {OUTPUT_JSON_PATH}\")"
      ],
      "metadata": {
        "id": "u19Yo8Fc0Gl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 步驟 1: 定義PDF文字擷取函式 ---\n",
        "\n",
        "def extract_text_from_pdf(pdf_path: str) -> str | None:\n",
        "    \"\"\"\n",
        "    使用PyMuPDF從PDF文件中擷取所有文字。\n",
        "    處理擷取過程中可能發生的錯誤。\n",
        "    \"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        for page_num in range(doc.page_count):\n",
        "            page = doc.load_page(page_num)\n",
        "            text += page.get_text() # 串接所有頁面的文字\n",
        "        doc.close()\n",
        "    except Exception as e:\n",
        "        print(f\"錯誤：從 {pdf_path} 擷取文字失敗: {e}\")\n",
        "        return None\n",
        "    return text\n",
        "\n",
        "print(\"`extract_text_from_pdf` 函式已定義。\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3r28eNBX0VPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 步驟 2: 定義案件字號擷取函式 (正規表達式) ---\n",
        "\n",
        "def extract_case_number(text: str) -> str | None:\n",
        "    \"\"\"\n",
        "    從文件文字中擷取台灣法院的案件字號 (案號)。\n",
        "    正規化：移除空格，並將 '臺' 替換為 '台'。\n",
        "    \"\"\"\n",
        "    regex_pattern = r'^(?:[\\s\\S]*?)?(?P<court_name>臺灣[\\u4E00-\\u9FFF\\s]{2,10}?(?:地方法院|高等法院|最高法院))([\\u4E00-\\u9FFF\\s]{1,15})?\\s*(?P<year>\\d{2,3})年度(?P<case_type>[\\u4E00-\\u9FFF]{1,5}?)字第(?P<number>\\d+)號'\n",
        "    match = re.search(regex_pattern, text, re.MULTILINE)\n",
        "\n",
        "    if match:\n",
        "        court_name = match.group('court_name').strip()\n",
        "        year = match.group('year')\n",
        "        case_type = match.group('case_type').strip()\n",
        "        number = match.group('number')\n",
        "\n",
        "        full_extracted_id = f\"{court_name}{year}年度{case_type}字第{number}號\"\n",
        "        cleaned_id = full_extracted_id.replace(' ', '').replace('臺', '台')\n",
        "        return cleaned_id\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "print(\"`extract_case_number` 函式已定義。\")\n",
        "\n"
      ],
      "metadata": {
        "id": "NQm1ZpQL0Xq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 步驟 3: 定義主文件處理函式 ---\n",
        "\n",
        "def process_all_documents(pdf_dir: str, output_file: str) -> list[dict]:\n",
        "    \"\"\"\n",
        "    處理指定資料夾中的所有PDF文件，並將結果儲存為JSON。\n",
        "    文件ID直接使用PDF檔名 (不含副檔名)。\n",
        "    \"\"\"\n",
        "    processed_documents = {}\n",
        "\n",
        "    print(f\"\\n--- 開始處理PDF文件，路徑來自: {pdf_dir} ---\")\n",
        "    if not os.path.exists(pdf_dir):\n",
        "        print(f\"警告: 找不到PDF資料夾，路徑位於 {pdf_dir}。跳過PDF處理。\")\n",
        "        return []\n",
        "\n",
        "    pdf_files = [f for f in os.listdir(pdf_dir) if f.lower().endswith('.pdf')]\n",
        "    print(f\"找到 {len(pdf_files)} 個PDF文件。\")\n",
        "\n",
        "    for filename in tqdm(pdf_files, desc=\"處理PDF文件\"):\n",
        "        pdf_path = os.path.join(pdf_dir, filename)\n",
        "        doc_content = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "        # 文件ID直接來自PDF檔名 (移除.pdf副檔名)\n",
        "        document_id = filename[:-4].strip().replace(' ', '').replace('臺', '台')\n",
        "        document_notes = []\n",
        "\n",
        "        if doc_content:\n",
        "            # 嘗試從內容中擷取案件字號 (用於後續Gemini分析參考)\n",
        "            extracted_case_number_from_content = extract_case_number(doc_content)\n",
        "            if extracted_case_number_from_content is None:\n",
        "                document_notes.append(\"在PDF內容中未能找到標準案件字號。\")\n",
        "            elif extracted_case_number_from_content != document_id:\n",
        "                document_notes.append(\n",
        "                    f\"文件ID '{document_id}' 與內容擷取到的案件字號 '{extracted_case_number_from_content}' 不符。\"\n",
        "                )\n",
        "\n",
        "            # 將文件資訊加入處理清單\n",
        "            processed_documents[document_id] = {\n",
        "                \"document_id\": document_id,\n",
        "                \"original_source_format\": \"PDF\",\n",
        "                \"original_filename\": filename,\n",
        "                \"full_text\": doc_content,\n",
        "                \"extracted_case_number_from_content\": extracted_case_number_from_content,\n",
        "                \"notes\": document_notes if document_notes else [\"文件ID來自檔名。\"]\n",
        "            }\n",
        "        else:\n",
        "            print(f\"跳過PDF文件 '{filename}'，因文字擷取錯誤 (例如：PDF格式不正確)。\")\n",
        "            document_notes.append(\"文字擷取失敗。\")\n",
        "            processed_documents[document_id] = {\n",
        "                \"document_id\": document_id,\n",
        "                \"original_source_format\": \"PDF\",\n",
        "                \"original_filename\": filename,\n",
        "                \"full_text\": None,\n",
        "                \"extracted_case_number_from_content\": None,\n",
        "                \"notes\": document_notes\n",
        "            }\n",
        "\n",
        "\n",
        "    print(f\"PDF處理完成。目前識別出 {len(processed_documents)} 個文件。\")\n",
        "\n",
        "    final_output_data = list(processed_documents.values())\n",
        "\n",
        "    # 將整合後的資料儲存至JSON檔案\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(final_output_data, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"所有處理過的文件資料已儲存至Colab環境中的 '{output_file}'。\")\n",
        "\n",
        "    return final_output_data\n",
        "\n",
        "print(\"`process_all_documents` 函式已定義。\")\n",
        "\n",
        "# --- 步驟 4: 執行文件處理 ---\n",
        "\n",
        "# 確保您的Google雲端硬碟已掛載！\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "final_documents_data = process_all_documents(PDF_FOLDER_PATH, OUTPUT_JSON_PATH)\n",
        "\n",
        "print(f\"\\n`process_all_documents` 執行完成。總計識別出獨特文件數: {len(final_documents_data)}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "r0iAHLSs0a16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 步驟 5: 檢查輸出結果 ---\n",
        "\n",
        "if os.path.exists(OUTPUT_JSON_PATH):\n",
        "    with open(OUTPUT_JSON_PATH, 'r', encoding='utf-8') as f:\n",
        "        processed_data = json.load(f)\n",
        "\n",
        "    print(f\"\\n--- 處理後資料範例 ({len(processed_data)} 總文件數) ---\")\n",
        "    for i, doc in enumerate(processed_data[:5]): # 顯示前5個文件\n",
        "        print(f\"\\n文件 {i+1}:\")\n",
        "        for key, value in doc.items():\n",
        "            if key == \"full_text\" and isinstance(value, str) and len(value) > 200:\n",
        "                print(f\"  {key}: {value[:200]}... (已截斷)\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "    if len(processed_data) > 5:\n",
        "        print(\"\\n... (僅顯示前5個文件)\")\n",
        "\n",
        "    print(f\"\\n--- 範例結束 ---\")\n",
        "\n",
        "else:\n",
        "    print(f\"錯誤: 輸出檔案 '{OUTPUT_JSON_PATH}' 未找到。請確認步驟 4 成功執行。\")\n",
        "\n"
      ],
      "metadata": {
        "id": "2hWIbaTN0dnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 步驟 6: 使用Gemini API分析文件 ---\n",
        "\n",
        "# 輔助函式：將民國紀年轉換為西元紀年\n",
        "def convert_roc_to_ad(roc_year_str: str) -> str | None:\n",
        "    \"\"\"\n",
        "    將中華民國紀年轉換為西元紀年。\n",
        "    例如：輸入 '112' 得到 '2023'。\n",
        "    \"\"\"\n",
        "    try:\n",
        "        roc_year = int(roc_year_str)\n",
        "        ad_year = roc_year + 1911\n",
        "        return str(ad_year)\n",
        "    except (ValueError, TypeError):\n",
        "        return None\n",
        "\n",
        "# 載入已處理的法律文件\n",
        "if not os.path.exists(OUTPUT_JSON_PATH):\n",
        "    print(f\"錯誤: 輸出檔案 '{OUTPUT_JSON_PATH}' 未找到。請確認先前的步驟已成功執行。\")\n",
        "    # 不退出，讓後續步驟有機會處理其他錯誤\n",
        "else:\n",
        "    with open(OUTPUT_JSON_PATH, 'r', encoding='utf-8') as f:\n",
        "        processed_data_for_gemini = json.load(f)\n",
        "\n",
        "    # 設定Gemini API\n",
        "    # 請確保您已在 Colab 環境的 Secrets 中設定 'GOOGLE_API_KEY'\n",
        "    # 在左側面板找到 '🔑' 圖標，點擊後新增一個密鑰，名稱設定為 'GOOGLE_API_KEY'，值貼上您的 Gemini API 金鑰。\n",
        "    try:\n",
        "        genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    except KeyError:\n",
        "        print(\"錯誤: Colab Secrets中未找到 'GOOGLE_API_KEY'。請新增！\")\n",
        "        # 不退出，讓後續步驟有機會處理其他錯誤\n",
        "    except Exception as e:\n",
        "        print(f\"設定 Gemini API 時發生錯誤: {e}\")\n",
        "        # 不退出，讓後續步驟有機會處理其他錯誤\n",
        "\n",
        "\n",
        "    # 定義系統指令\n",
        "    system_instruction_text = \"\"\"\n",
        "    您是一位在台灣法律領域具有深厚專業知識的人工智慧助理。\n",
        "    您專精於分析與《緊急醫療救護法》相關的法律文件，並擁有豐富的法務助理（paralegal）經驗，特別擅長從台灣司法院裁判書系統下載的刑事裁判文書中精準提取關鍵資訊。\n",
        "\n",
        "    您的核心職責是提供客觀、公正且不帶偏見的分析，旨在清晰描繪緊急醫療救護技術員（EMT）在刑事案件中的專業責任面貌。請務必確保您的資訊提取過程嚴謹，並僅基於文件內容，避免任何推斷或個人意見。\n",
        "\n",
        "    您的所有回應應遵循指令，並以清晰、結構化的方式呈現。\n",
        "    \"\"\"\n",
        "\n",
        "    # 初始化Gemini模型，優先使用system_instruction參數\n",
        "    try:\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash-latest',\n",
        "                                      system_instruction=system_instruction_text)\n",
        "        _system_instruction_set_flag = True\n",
        "    except TypeError:\n",
        "        print(\"警告: 模型初始化不直接支援 `system_instruction` 參數。將系統指令附加到使用者提示中。\")\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "        _system_instruction_set_flag = False\n",
        "    except Exception as e:\n",
        "        print(f\"初始化 Gemini 模型時發生錯誤: {e}\")\n",
        "        # 如果模型初始化失敗，後續的 API 呼叫會出錯，但我們還是讓程式繼續，以便使用者看到錯誤訊息\n",
        "\n",
        "    print(\"\\n--- 開始Gemini API綜合分析 ---\")\n",
        "\n",
        "    updated_processed_data_final = []\n",
        "    num_processed = 0\n",
        "\n",
        "    # 根據 DOCUMENT_PROCESS_LIMIT 限制處理的文件數量\n",
        "    documents_to_process = processed_data_for_gemini\n",
        "    if DOCUMENT_PROCESS_LIMIT is not None:\n",
        "        documents_to_process = processed_data_for_gemini[:DOCUMENT_PROCESS_LIMIT]\n",
        "\n",
        "    # 檢查模型是否成功初始化\n",
        "    if 'model' not in locals():\n",
        "         print(\"錯誤: Gemini 模型未能成功初始化。跳過 API 分析步驟。\")\n",
        "         updated_processed_data_final = processed_data_for_gemini # 將原始資料複製到最終結果\n",
        "    else:\n",
        "        for doc in tqdm(documents_to_process, desc=\"使用Gemini分析文件\"):\n",
        "            full_text = doc.get(\"full_text\", \"\")\n",
        "            document_id = doc.get(\"document_id\", \"N/A\")\n",
        "\n",
        "            # 跳過內容過短或無明顯法律背景的文件\n",
        "            if not full_text or len(full_text) < 500:\n",
        "                doc[\"extracted_legal_data\"] = {\"status\": \"skipped_too_short\"}\n",
        "                if \"notes\" not in doc:\n",
        "                    doc[\"notes\"] = []\n",
        "                elif not isinstance(doc[\"notes\"], list):\n",
        "                     doc[\"notes\"] = [doc[\"notes\"]]\n",
        "                doc[\"notes\"].append(\"跳過綜合分析 (文字過短)。\")\n",
        "                updated_processed_data_final.append(doc)\n",
        "                continue\n",
        "\n",
        "            # 針對Gemini的綜合使用者提示\n",
        "            user_prompt_text = f\"\"\"\n",
        "            請仔細分析以下台灣刑事裁判文件，並精準提取所有要求資訊。請按照指定的 JSON 格式輸出，若某項資訊未找到，請將其值設為 `null` 或空陣列 `[]`（依資料類型而定）。\n",
        "\n",
        "            文件內容：\n",
        "            ---\n",
        "            {full_text[:6000]}\n",
        "            ---\n",
        "\n",
        "            請提取以下資訊：\n",
        "\n",
        "            1.  救護技術員姓名 (emergency_medical_technicians):\n",
        "                列出文件中所有被提及為「救護技術員」或「救護人員」的個人姓名。姓名通常為繁體中文，且大多數為三個漢字。請將所有找到的姓名收集在一個字串陣列中。\n",
        "\n",
        "            2.  救護技術員等級 (emt_grade):\n",
        "                判斷文件中提及的「救護技術員」的等級。請從「初級救護員 (EMT1)」、「中級救護員 (EMT2)」、「高級救護員 (EMTP)」中選擇。請勿將僅有基本CPR或AED訓練的非執業人員（如劉欣華案例）混淆為救護技術員。\n",
        "\n",
        "            3.  救護技術員雇主 (emt_employer):\n",
        "                識別文件中提及的救護技術員所受雇的機構或公司。請尋找如「受雇於」或相關語句後的雇主名稱。例如：「救護車有限公司」、「醫院」。\n",
        "\n",
        "            4.  救護技術員任務 (emt_mission):\n",
        "                根據文件內容，判斷救護技術員當時執行的是何種勤務或任務。任務可能包括「送病患至醫院」、「返家護送」、「安寧返家」或其他描述。請尋找「執行勤務」等關鍵詞後的任務描述。\n",
        "\n",
        "            5.  救護技術員法律角色 (emt_role):\n",
        "                判斷救護技術員在該案件中的法律角色。請從「原告」、「告訴人」、「被告」、「證人」或「被害人」中選擇一個最符合的。每個救護技術員都應有一個角色。\n",
        "\n",
        "            6.  辯護人存在 (defense_attorney):\n",
        "                判斷在文件開頭部分是否存在「辯護人」（例如「選任辯護人」）。請以布林值 (true/false) 回應。\n",
        "\n",
        "            7.  衛福部醫事審議委員會鑑定書存在 (mohw_involve):\n",
        "                判斷文件中是否提及「衛福部醫事審議委員會鑑定書」或其別名（如「衛生福利部審議」、「委員會鑑定書」）。請以布林值 (true/false) 回應。請勿與交通事故相關資料混淆。\n",
        "\n",
        "            8.  是否為公訴案件 (public_prosec):\n",
        "                判斷本案是否為「公訴」案件。請在文件開頭部分尋找「公訴人」，並進一步確認其後是否跟隨「檢察官」。若符合，請以布林值 (true/false) 回應。\n",
        "\n",
        "            9.  事件發生日期 (date_incident):\n",
        "                提取事件發生的日期。此資訊常在「經查」或「唯查」段落。請將中華民國紀年轉換為西元紀年，格式為YYYY-MM-DD。\n",
        "\n",
        "            10. 上訴日期 (date_appeal):\n",
        "                提取上訴提出的日期。此資訊常在文件上半部（前5段），如「委任***律師向本院聲請」後的日期。若無上訴日期，請設為null。請將中華民國紀年轉換為西元紀年，格式為YYYY-MM-DD。\n",
        "\n",
        "            11. 裁判日期 (date_trial):\n",
        "                提取裁判文書的判決日期。此資訊通常在文件末尾，法官姓名列表之後。請勿與書記官後的日期混淆。文件中必定存在此日期。請將中華民國紀年轉換為西元紀年，格式為YYYY-MM-DD。\n",
        "\n",
        "            12. 事件發生縣市 (county_incident):\n",
        "                提取事件發生的縣市名稱。此資訊常在「經查」或「唯查」段落。例如：「嘉義縣」、「高雄市」。\n",
        "\n",
        "            13. 案件字號 (case_id):\n",
        "                提取文件開頭「裁判字號」或標題後方的案件字號。例如：「臺灣彰化地方法院107年度交易字第810號」。請省略「刑事判決」或「刑事裁定」字樣，並移除空格。請勿與「公訴人檢察官」混淆。\n",
        "\n",
        "            14. 承辦法院 (case_court):\n",
        "                從案件字號中提取負責審理本案的法院名稱。例如：「臺灣彰化地方法院」。\n",
        "\n",
        "            15. 案由 (cause_of_action):\n",
        "                提取原告上訴（或檢察官起訴）被告的「案由」。此資訊在「裁判案由」或「犯罪事實」段落中至關重要。若有「聲請交付審判」，請繼續解析直至找到真正的案由。例如：「業務過失致重傷害」、「業務過失致死」、「過失傷害」。\n",
        "\n",
        "\n",
        "            請以單一 JSON 物件回應，包含以下鍵值對：\n",
        "            {{\n",
        "              \"emergency_medical_technicians\": [], // 字串陣列\n",
        "              \"emt_grade\": null, // 字串: \"初級救護員 (EMT1)\", \"中級救護員 (EMT2)\", \"高級救護員 (EMTP)\", 或 null\n",
        "              \"emt_employer\": null, // 字串\n",
        "              \"emt_mission\": null, // 字串\n",
        "              \"emt_role\": null, // 字串: \"原告\", \"告訴人\", \"被告\", \"證人\", \"被害人\", 或 null\n",
        "              \"defense_attorney\": null, // 布林值: true/false\n",
        "              \"mohw_involve\": null, // 布林值: true/false\n",
        "              \"public_prosec\": null, // 布林值: true/false\n",
        "              \"date_incident\": null, // 字串:YYYY-MM-DD 或 null\n",
        "              \"date_appeal\": null, // 字串:YYYY-MM-DD 或 null\n",
        "              \"date_trial\": null, // 字串:YYYY-MM-DD\n",
        "              \"county_incident\": null, // 字串\n",
        "              \"case_id\": null, // 字串\n",
        "              \"case_court\": null, // 字串\n",
        "              \"cause_of_action\": null // 字串\n",
        "            }}\n",
        "            \"\"\"\n",
        "\n",
        "            final_prompt_for_gemini = user_prompt_text\n",
        "            if not _system_instruction_set_flag:\n",
        "                final_prompt_for_gemini = system_instruction_text + \"\\n\" + user_prompt_text\n",
        "\n",
        "            try:\n",
        "                response = model.generate_content(\n",
        "                    final_prompt_for_gemini,\n",
        "                    generation_config=genai.types.GenerationConfig(\n",
        "                        temperature=0.0,\n",
        "                        max_output_tokens=1500\n",
        "                    ),\n",
        "                    safety_settings={\n",
        "                        'HARM_CATEGORY_HARASSMENT':'BLOCK_NONE',\n",
        "                        'HARM_CATEGORY_HATE_SPEECH':'BLOCK_NONE',\n",
        "                        'HARM_CATEGORY_SEXUALLY_EXPLICIT':'BLOCK_NONE',\n",
        "                        'HARM_CATEGORY_DANGEROUS_CONTENT':'BLOCK_NONE'\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                response_text = response.text.strip()\n",
        "                if response_text.startswith(\"```json\"):\n",
        "                    response_text = response_text[len(\"```json\"):].strip()\n",
        "                if response_text.endswith(\"```\"):\n",
        "                    response_text = response_text[:-len(\"```\")].strip()\n",
        "\n",
        "                extracted_data = {}\n",
        "                try:\n",
        "                    parsed_response = json.loads(response_text)\n",
        "                    extracted_data[\"emergency_medical_technicians\"] = parsed_response.get(\"emergency_medical_technicians\", [])\n",
        "                    extracted_data[\"emt_grade\"] = parsed_response.get(\"emt_grade\")\n",
        "                    extracted_data[\"emt_employer\"] = parsed_response.get(\"emt_employer\")\n",
        "                    extracted_data[\"emt_mission\"] = parsed_response.get(\"emt_mission\")\n",
        "                    extracted_data[\"emt_role\"] = parsed_response.get(\"emt_role\")\n",
        "                    extracted_data[\"defense_attorney\"] = parsed_response.get(\"defense_attorney\")\n",
        "                    extracted_data[\"mohw_involve\"] = parsed_response.get(\"mohw_involve\")\n",
        "                    extracted_data[\"public_prosec\"] = parsed_response.get(\"public_prosec\")\n",
        "                    extracted_data[\"date_incident\"] = parsed_response.get(\"date_incident\")\n",
        "                    extracted_data[\"date_appeal\"] = parsed_response.get(\"date_appeal\")\n",
        "                    extracted_data[\"date_trial\"] = parsed_response.get(\"date_trial\")\n",
        "                    extracted_data[\"county_incident\"] = parsed_response.get(\"county_incident\")\n",
        "                    extracted_data[\"case_id\"] = parsed_response.get(\"case_id\")\n",
        "                    extracted_data[\"case_court\"] = parsed_response.get(\"case_court\")\n",
        "                    extracted_data[\"cause_of_action\"] = parsed_response.get(\"cause_of_action\")\n",
        "\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"警告: Gemini未回傳有效JSON，文件ID: {document_id}。回應: {response_text[:200]}...\")\n",
        "                    extracted_data = {\"status\": \"json_parse_error\", \"raw_response\": response_text}\n",
        "                except AttributeError as ae:\n",
        "                     print(f\"警告: Gemini回傳非預期結構，文件ID: {document_id}。錯誤: {ae}。回應: {response_text[:200]}...\")\n",
        "                     extracted_data = {\"status\": \"structure_error\", \"raw_response\": response_text}\n",
        "\n",
        "                doc[\"extracted_legal_data\"] = extracted_data\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"使用Gemini API處理文件 {document_id} 時發生錯誤: {e}\")\n",
        "                doc[\"extracted_legal_data\"] = {\"status\": \"api_error\", \"error_message\": str(e)}\n",
        "                if \"notes\" not in doc:\n",
        "                    doc[\"notes\"] = []\n",
        "                elif not isinstance(doc[\"notes\"], list):\n",
        "                     doc[\"notes\"] = [doc[\"notes\"]]\n",
        "                doc[\"notes\"].append(f\"Gemini API綜合分析錯誤: {e}\")\n",
        "\n",
        "            updated_processed_data_final.append(doc)\n",
        "            num_processed += 1\n",
        "\n",
        "        print(f\"--- Gemini API綜合分析完成。已處理 {num_processed} 個文件。 ---\")\n",
        "\n",
        "        # 將包含 Gemini 分析結果的資料儲存回 JSON 檔案\n",
        "        try:\n",
        "            with open(OUTPUT_JSON_PATH, 'w', encoding='utf-8') as f:\n",
        "                json.dump(updated_processed_data_final, f, ensure_ascii=False, indent=2)\n",
        "            print(f\"包含所有擷取法律欄位的處理後資料已儲存回 '{OUTPUT_JSON_PATH}'。\")\n",
        "        except Exception as e:\n",
        "            print(f\"儲存更新後的 JSON 檔案時發生錯誤: {e}\")\n",
        "\n",
        "\n",
        "    print(\"\\n--- 包含法律欄位的更新後處理資料範例 (前3個經Gemini處理或跳過的文件) ---\")\n",
        "    display_count = 0\n",
        "    for doc in updated_processed_data_final:\n",
        "        if \"extracted_legal_data\" in doc:\n",
        "            print(f\"\\n文件 (ID: {doc.get('document_id', 'N/A')}):\")\n",
        "            print(f\"  擷取資料: {json.dumps(doc.get('extracted_legal_data', {}), ensure_ascii=False, indent=2)}\")\n",
        "            print(f\"  備註: {doc.get('notes', 'N/A')}\")\n",
        "            display_count += 1\n",
        "        # 也顯示跳過的文件，以確認所有文件都被考慮到\n",
        "        elif \"notes\" in doc and \"跳過綜合分析\" in \"\".join(doc[\"notes\"]):\n",
        "             print(f\"\\n文件 (ID: {doc.get('document_id', 'N/A')}):\")\n",
        "             print(f\"  狀態: 已跳過\")\n",
        "             print(f\"  備註: {doc.get('notes', 'N/A')}\")\n",
        "             display_count += 1\n",
        "\n",
        "        if display_count >= 3:\n",
        "            break\n",
        "    if display_count == 0:\n",
        "        print(\"沒有經Gemini處理或明確標記跳過的文件可供顯示。\")\n",
        "\n",
        "    print(\"\\n--- 範例結束 ---\")"
      ],
      "metadata": {
        "id": "lXY3o_x80xHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# --- 步驟 0: 環境準備與設定 ---\n",
        "\n",
        "# 確保您的Google雲端硬碟已掛載 (如果您的 JSON 檔案儲存在雲端硬碟)\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive') # 如果您的 JSON 檔案儲存在雲端硬碟，請取消註解此行\n",
        "\n",
        "# 安裝處理Excel檔案所需的函式庫 (如果尚未安裝)\n",
        "!pip install -q openpyxl pandas\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "print(\"函式庫載入完成，並已掛載Google雲端硬碟 (若需要)。\")\n",
        "\n",
        "# --- 設定檔案路徑 ---\n",
        "# 請確認這裡的 JSON_FILE_PATH 與您產生 JSON 檔案的路徑一致\n",
        "# 範例：JSON_FILE_PATH = '/content/processed_documents.json'\n",
        "# 範例：JSON_FILE_PATH = '/content/drive/MyDrive/processed_legal_documents.json'\n",
        "\n",
        "# 請在此處指定您的輸入 JSON 檔案路徑\n",
        "JSON_FILE_PATH = '/content/drive/MyDrive/processed_legal_documents.json' # <-- 請修改此路徑\n",
        "\n",
        "# 輸出 CSV/Excel 的資料夾 (將根據 JSON 檔案的路徑自動設置)\n",
        "OUTPUT_DIR = os.path.dirname(JSON_FILE_PATH)\n",
        "# 如果 JSON_FILE_PATH 是相對路徑或沒有目錄，OUTPUT_DIR 將是空字串或 '.'\n",
        "# 在這種情況下，我們將輸出檔案儲存在 Colab 的 /content 目錄下\n",
        "if not OUTPUT_DIR or OUTPUT_DIR == '.':\n",
        "    OUTPUT_DIR = '/content'\n",
        "\n",
        "# CSV 輸出檔案路徑\n",
        "OUTPUT_CSV_FILE = os.path.join(OUTPUT_DIR, 'processed_legal_documents_exploded.csv')\n",
        "\n",
        "# Excel 輸出檔案路徑\n",
        "OUTPUT_EXCEL_FILE = os.path.join(OUTPUT_DIR, 'processed_legal_documents_exploded.xlsx')\n",
        "\n",
        "print(f\"將從 '{JSON_FILE_PATH}' 讀取資料。\")\n",
        "print(f\"CSV 檔案將儲存至: '{OUTPUT_CSV_FILE}'\")\n",
        "print(f\"Excel 檔案將儲存至: '{OUTPUT_EXCEL_FILE}'\")\n",
        "\n",
        "# --- 步驟 1: 讀取 JSON 並轉換為 Pandas DataFrame ---\n",
        "try:\n",
        "    with open(JSON_FILE_PATH, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    # 將主要資料轉換為 DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 處理 'extracted_legal_data' 巢狀字典\n",
        "    # 先將 'extracted_legal_data' 轉換為 DataFrame\n",
        "    # 使用 errors='ignore' 處理可能不存在 'extracted_legal_data' 的行\n",
        "    extracted_df = pd.json_normalize(df['extracted_legal_data'], errors='ignore')\n",
        "\n",
        "    # --- 重要修改: 使用 explode() 來展開 'emergency_medical_technicians' 為獨立的列 ---\n",
        "    if 'emergency_medical_technicians' in extracted_df.columns:\n",
        "        # 確保 'emergency_medical_technicians' 欄位是列表型態，以便 explode 正常運作\n",
        "        # 將非列表的值（例如 null, 字符串）轉換為包含單個值的列表或空列表\n",
        "        extracted_df['emergency_medical_technicians'] = extracted_df['emergency_medical_technicians'].apply(\n",
        "            lambda x: x if isinstance(x, list) else ([x] if x is not None else [])\n",
        "        )\n",
        "        # 執行 explode，讓每個姓名成為一個獨立的列，並複製其他相關欄位\n",
        "        # 使用 ignore_index=True 以便後續合併\n",
        "        extracted_df_exploded = extracted_df.explode('emergency_medical_technicians', ignore_index=True)\n",
        "\n",
        "        # 可選: 移除展開後可能產生的空字串行 (如果原列表中有空字串或 None)\n",
        "        # extracted_df_exploded = extracted_df_exploded[extracted_df_exploded['emergency_medical_technicians'].astype(bool)]\n",
        "\n",
        "        # 為了合併，我們需要將原始 df 的行與 exploded 後的行對應起來\n",
        "        # 最簡單的方法是將原始 df 的每一行與其對應的 exploded 行合併\n",
        "        # 但 explode 改變了行數，所以直接 join 會複雜\n",
        "        # 更好的方法是只處理原始 df 中非列表欄位，然後與 exploded 後的 extracted_df 合併\n",
        "        # 我們需要一個共同的鍵。原始 df 的索引可以作為這個鍵\n",
        "        df['original_index'] = df.index # 為原始 df 添加索引列\n",
        "\n",
        "        # 將處理後的 extracted_df_exploded (帶有原始索引資訊) 與原始 df 合併\n",
        "        # 注意：這一步需要 extracted_df_exploded 中有某種方式可以追蹤回原始 df 的索引\n",
        "        # explode(ignore_index=True) 會丟失原始索引。\n",
        "        # 讓我們重新考慮 explode 的使用方式，保留原始索引\n",
        "        extracted_df_with_original_index = pd.json_normalize(data, record_path='extracted_legal_data', meta=['document_id', 'original_source_format', 'original_filename', 'notes'], errors='ignore')\n",
        "\n",
        "        # 現在 extracted_df_with_original_index 包含了原始 document_id 和其他元數據\n",
        "        # 我們可以在這個 DataFrame 上進行 explode\n",
        "        if 'emergency_medical_technicians' in extracted_df_with_original_index.columns:\n",
        "             extracted_df_with_original_index['emergency_medical_technicians'] = extracted_df_with_original_index['emergency_medical_technicians'].apply(\n",
        "                lambda x: x if isinstance(x, list) else ([x] if x is not None else [])\n",
        "            )\n",
        "             final_df = extracted_df_with_original_index.explode('emergency_medical_technicians', ignore_index=True)\n",
        "\n",
        "        # 處理原始 df 中的列表欄位 (例如 notes) - 現在這些已經在 extracted_df_with_original_index 中了\n",
        "        # 確保 notes 欄位是字串\n",
        "        if 'notes' in final_df.columns:\n",
        "            final_df['notes'] = final_df['notes'].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
        "\n",
        "        # 可選: 處理 'full_text' 欄位\n",
        "        # 預設：移除 'full_text' 欄位\n",
        "        if 'full_text' in final_df.columns: # 確保 'full_text' 列存在\n",
        "             final_df = final_df.drop(columns=['full_text'])\n",
        "\n",
        "    else:\n",
        "        # 如果沒有 emergency_medical_technicians 欄位，或者根本沒有 extracted_legal_data\n",
        "        # 直接將原始 df 扁平化，不進行 explode\n",
        "        final_df = pd.json_normalize(data, errors='ignore')\n",
        "        # 處理原始 df 中的列表欄位 (例如 notes)\n",
        "        for col in ['notes', 'judges']: # 如果您保留了法官姓名擷取，'judges' 會存在\n",
        "            if col in final_df.columns:\n",
        "                final_df[col] = final_df[col].apply(lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x)\n",
        "        # 可選: 處理 'full_text' 欄位\n",
        "        if 'full_text' in final_df.columns:\n",
        "            final_df = final_df.drop(columns=['full_text'])\n",
        "\n",
        "\n",
        "    # 重新排列欄位順序，將 extracted_legal_data 相關的欄位放在一起\n",
        "    # 首先獲取所有欄位名稱\n",
        "    all_cols = final_df.columns.tolist()\n",
        "\n",
        "    # 定義您想要放在前面的欄位順序\n",
        "    preferred_order_prefix = [\n",
        "        'document_id',\n",
        "        'original_filename',\n",
        "        'original_source_format',\n",
        "        'notes',\n",
        "        'extracted_legal_data.status', # 如果存在的話\n",
        "        'extracted_legal_data.error_message', # 如果存在的話\n",
        "        'extracted_legal_data.raw_response', # 如果存在的話\n",
        "        'extracted_legal_data.case_id',\n",
        "        'extracted_legal_data.case_court',\n",
        "        'extracted_legal_data.cause_of_action',\n",
        "        'extracted_legal_data.date_trial',\n",
        "        'extracted_legal_data.date_incident',\n",
        "        'extracted_legal_data.county_incident',\n",
        "        'emergency_medical_technicians', # 展開後的 EMT 姓名\n",
        "        'extracted_legal_data.emt_grade',\n",
        "        'extracted_legal_data.emt_employer',\n",
        "        'extracted_legal_data.emt_mission',\n",
        "        'extracted_legal_data.emt_role',\n",
        "        'extracted_legal_data.defense_attorney',\n",
        "        'extracted_legal_data.mohw_involve',\n",
        "        'extracted_legal_data.public_prosec',\n",
        "        'extracted_legal_data.date_appeal',\n",
        "    ]\n",
        "\n",
        "    # 過濾出實際存在於 final_df 中的 preferred 欄位\n",
        "    preferred_cols_existing = [col for col in preferred_order_prefix if col in all_cols]\n",
        "\n",
        "    # 找出所有不在 preferred 列表中的欄位\n",
        "    other_cols = [col for col in all_cols if col not in preferred_cols_existing]\n",
        "\n",
        "    # 組合最終的欄位順序 (preferred 欄位在前，其餘欄位在後)\n",
        "    final_col_order = preferred_cols_existing + other_cols\n",
        "\n",
        "    # 重新索引 DataFrame 以應用新的欄位順序\n",
        "    final_df = final_df[final_col_order]\n",
        "\n",
        "\n",
        "    print(\"JSON 資料已成功讀取、展開並轉換為 DataFrame。\")\n",
        "    print(\"DataFrame 前 5 行預覽:\")\n",
        "    display(final_df.head()) # 使用 display 獲得更好的格式\n",
        "    print(f\"DataFrame 形狀: {final_df.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"錯誤: 未找到 JSON 檔案。請確認路徑 '{JSON_FILE_PATH}' 正確。\")\n",
        "except json.JSONDecodeError:\n",
        "    print(f\"錯誤: JSON 檔案 '{JSON_FILE_PATH}' 格式不正確。\")\n",
        "except Exception as e:\n",
        "    print(f\"處理資料時發生未知錯誤: {e}\")\n",
        "\n",
        "# --- 步驟 2: 儲存為 CSV 和 Excel 檔案 ---\n",
        "# 只有在 final_df 成功創建時才嘗試儲存\n",
        "if 'final_df' in locals() and not final_df.empty:\n",
        "    try:\n",
        "        final_df.to_csv(OUTPUT_CSV_FILE, index=False, encoding='utf-8-sig') # 'utf-8-sig' 避免中文亂碼\n",
        "        print(f\"資料已成功儲存為 CSV 檔案: '{OUTPUT_CSV_FILE}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"儲存 CSV 檔案時發生錯誤: {e}\")\n",
        "\n",
        "    try:\n",
        "        final_df.to_excel(OUTPUT_EXCEL_FILE, index=False, engine='openpyxl')\n",
        "        print(f\"資料已成功儲存為 Excel 檔案: '{OUTPUT_EXCEL_FILE}'\")\n",
        "    except Exception as e:\n",
        "        print(f\"儲存 Excel 檔案時發生錯誤: {e}\")\n",
        "\n",
        "    print(\"\\n轉換完成！您現在可以在 Google 雲端硬碟或 Colab 環境中找到 CSV 和 Excel 檔案。\")\n",
        "elif 'final_df' in locals() and final_df.empty:\n",
        "    print(\"\\nDataFrame 為空，未執行 CSV/Excel 儲存。請檢查輸入 JSON 檔案是否包含資料。\")\n",
        "else:\n",
        "    print(\"\\nDataFrame 未成功建立，未執行 CSV/Excel 儲存。請檢查之前的錯誤訊息。\")"
      ],
      "metadata": {
        "id": "iW4ovi0s4CMW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}